{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import os\n",
    "import sys\n",
    "import torch\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import davies_bouldin_score\n",
    "from sklearn.cluster import KMeans\n",
    "from adjustText import adjust_text\n",
    "from IPython.display import display\n",
    "\n",
    "sys.path.append('../src')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare for comparison\n",
    "# Load ImageNet classnames as texts\n",
    "from open_clip import IMAGENET_CLASSNAMES\n",
    "\n",
    "\n",
    "# Load tuple from file\n",
    "def load_tuple(filename):\n",
    "    with open(filename, 'rb') as file:\n",
    "        return pickle.load(file)\n",
    "\n",
    "\n",
    "IMAGENET_CLASSNAMES_ZH = load_tuple(\"./results/imagenet_classnames_zh.pkl\")\n",
    "\n",
    "# Load several text embeddings from ../data/ImageNet/text_embeds/\n",
    "imagenet_overall_prompt_bert_tiny_uncased = torch.load(\n",
    "    \"../data/ImageNet/text_embeds/imagenet_overall_prompt_bert_tiny_uncased.pt\").t()\n",
    "imagenet_overall_prompt_flan_t5_xxl = torch.load(\n",
    "    \"../data/ImageNet/text_embeds/imagenet_overall_prompt_flan_t5_xxl.pt\").t()\n",
    "imagenet_single_template_bert_tiny_uncased = torch.load(\n",
    "    \"../data/ImageNet/text_embeds/imagenet_single_template_bert_tiny_uncased.pt\").t()\n",
    "imagenet_single_template_flan_t5_xxl = torch.load(\n",
    "    \"../data/ImageNet/text_embeds/imagenet_single_template_flan_t5_xxl.pt\").t()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# progress_output = display('', display_id=True)\n",
    "\n",
    "\n",
    "def print_progress(iteration, total):\n",
    "    # progress_output.update(\n",
    "    #     f\"Adjusting text: {iteration}/{total} iterations completed\")\n",
    "    print(f\"Adjusting text: {iteration}/{total} iterations completed\")\n",
    "\n",
    "\n",
    "def tsne_plot(plot_name, avoid_text_overlap, tensor_data, labels, apply_scaling, **tsne_kwargs):\n",
    "    \"\"\"\n",
    "    Apply t-SNE on a given tensor and plot the results with labels.\n",
    "\n",
    "    Parameters:\n",
    "    plot_name (str): The name of the plot.\n",
    "    avoid_text_overlap (bool): Whether to use adjust_text to avoid text overlap.\n",
    "    tensor_data (torch.Tensor): An m x n tensor of data points.\n",
    "    labels (tuple of str): A tuple of strings representing the labels of each data point.\n",
    "    apply_scaling (bool): Whether to apply StandardScaler before t-SNE.\n",
    "    **tsne_kwargs: Additional keyword arguments for the t-SNE function.\n",
    "    \"\"\"\n",
    "    # Convert tensor to numpy array\n",
    "    data = tensor_data.detach().cpu().numpy()\n",
    "\n",
    "    # Apply StandardScaler if required\n",
    "    if apply_scaling:\n",
    "        scaler = StandardScaler()\n",
    "        data = scaler.fit_transform(data)\n",
    "\n",
    "    # Apply t-SNE\n",
    "    tsne = TSNE(**tsne_kwargs)\n",
    "    tsne_results = tsne.fit_transform(data)\n",
    "\n",
    "    # Plotting the results\n",
    "    plt.figure(figsize=(80, 80))\n",
    "    # plt.figure(figsize=(30, 30))\n",
    "    texts = []\n",
    "    for i, label in enumerate(labels):\n",
    "        plt.scatter(tsne_results[i, 0], tsne_results[i, 1])\n",
    "        if not avoid_text_overlap:\n",
    "            # pass\n",
    "            plt.annotate(\n",
    "                label,\n",
    "                (tsne_results[i, 0], tsne_results[i, 1]),\n",
    "                textcoords=\"offset points\",\n",
    "                fontproperties=\"SimHei\",\n",
    "                xytext=(0, 10), ha='center'\n",
    "            )\n",
    "        else:\n",
    "            texts.append(\n",
    "                plt.text(\n",
    "                    tsne_results[i, 0],\n",
    "                    tsne_results[i, 1],\n",
    "                    label,\n",
    "                    fontproperties=\"SimHei\",\n",
    "                    ha='center',\n",
    "                    va='center'),\n",
    "\n",
    "            )\n",
    "\n",
    "    if avoid_text_overlap:\n",
    "        # Use adjust_text to automatically adjust labels\n",
    "        adjust_text(\n",
    "            texts,\n",
    "            x=tsne_results[:, 0],\n",
    "            y=tsne_results[:, 1],\n",
    "            progress_callback=print_progress\n",
    "        )\n",
    "    title = f't-SNE plot of {plot_name}'\n",
    "    plt.title(title)\n",
    "    # plt.xlabel('t-SNE feature 1')\n",
    "    # plt.ylabel('t-SNE feature 2')\n",
    "    plt.savefig(\n",
    "        os.path.join('./results/', '_'.join(title.split(' ')) + '.pdf'),\n",
    "        format='pdf'\n",
    "        # os.path.join('./results/', '_'.join(title.split(' ')+['ppt']) + '.png'),\n",
    "        # format='png'\n",
    "    )\n",
    "    plt.show()\n",
    "\n",
    "    return tsne_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TSNE settings\n",
    "default_tsne_setting = {\n",
    "    # Dimension of the embedded space\n",
    "    'n_components': 2,\n",
    "    # Number of nearest neighbors to consider\n",
    "    'perplexity': 10,\n",
    "    # Controls how tight natural clusters in the original space are in the embedded space\n",
    "    'early_exaggeration': 12.0,\n",
    "    # The learning rate for t-SNE optimization\n",
    "    'learning_rate': 'auto',\n",
    "    # Maximum number of iterations for the optimization\n",
    "    'n_iter':1000,\n",
    "    # Maximum number of iterations without progress before stopping the optimization\n",
    "    'n_iter_without_progress': 300,\n",
    "    # If the gradient norm is below this threshold, the optimization will stop\n",
    "    'min_grad_norm': 1e-7,\n",
    "    # The metric to use when calculating distance between instances\n",
    "    'metric': 'cityblock',\n",
    "    # Initialization of embedding. Possible options are 'random', 'pca', and a numpy array\n",
    "    'init': 'pca',\n",
    "    # Seed for the random number generator\n",
    "    'random_state': 666,\n",
    "    # The algorithm for gradient descent ('barnes_hut' or 'exact')\n",
    "    'method': 'barnes_hut',\n",
    "    # 'method': 'exact',\n",
    "    # Trade-off between speed and accuracy for 'barnes_hut' method\n",
    "    'angle': 0.5,\n",
    "    # Maximum number of CPU cores used for the optimization\n",
    "    'n_jobs': 10,\n",
    "    # Verbosity level\n",
    "    'verbose': 1,\n",
    "}\n",
    "tsne_settings = {\n",
    "    \"imagenet_overall_prompt_bert_tiny_uncased\": default_tsne_setting,\n",
    "    \"imagenet_overall_prompt_flan_t5_xxl\": default_tsne_setting,\n",
    "    \"imagenet_single_template_bert_tiny_uncased\": default_tsne_setting,\n",
    "    \"imagenet_single_template_flan_t5_xxl\": default_tsne_setting\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tsne_imagenet_overall_prompt_bert_tiny_uncased = tsne_plot(\n",
    "    \"imagenet_overall_prompt_bert_tiny_uncased\",\n",
    "    # avoid_text_overlap=False,\n",
    "    avoid_text_overlap=True,\n",
    "    tensor_data=imagenet_overall_prompt_bert_tiny_uncased,\n",
    "    labels=IMAGENET_CLASSNAMES_ZH,\n",
    "    apply_scaling=True,\n",
    "    **tsne_settings[\"imagenet_overall_prompt_bert_tiny_uncased\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tsne_imagenet_overall_prompt_flan_t5_xxl = tsne_plot(\n",
    "    \"imagenet_overall_prompt_flan_t5_xxl\",\n",
    "    # avoid_text_overlap=False,\n",
    "    avoid_text_overlap=True,\n",
    "    tensor_data=imagenet_overall_prompt_flan_t5_xxl,\n",
    "    labels=IMAGENET_CLASSNAMES_ZH,\n",
    "    apply_scaling=True,\n",
    "    **tsne_settings[\"imagenet_overall_prompt_flan_t5_xxl\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tsne_imagenet_single_template_bert_tiny_uncased = tsne_plot(\n",
    "    \"imagenet_single_template_bert_tiny_uncased\",\n",
    "    # avoid_text_overlap=False,\n",
    "    avoid_text_overlap=True,\n",
    "    tensor_data=imagenet_single_template_bert_tiny_uncased,\n",
    "    labels=IMAGENET_CLASSNAMES_ZH,\n",
    "    apply_scaling=True,\n",
    "    **tsne_settings[\"imagenet_single_template_bert_tiny_uncased\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tsne_imagenet_single_template_flan_t5_xxl = tsne_plot(\n",
    "    \"imagenet_single_template_flan_t5_xxl\",\n",
    "    # avoid_text_overlap=False,\n",
    "    avoid_text_overlap=True,\n",
    "    tensor_data=imagenet_single_template_flan_t5_xxl,\n",
    "    labels=IMAGENET_CLASSNAMES_ZH,\n",
    "    apply_scaling=True,\n",
    "    **tsne_settings[\"imagenet_single_template_flan_t5_xxl\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_dbi(data_tensor, k, **kmeans_args):\n",
    "    \n",
    "    # Convert tensor to numpy array if it is a tensor for compatibility with sklearn\n",
    "    if isinstance(data_tensor, torch.Tensor):\n",
    "        data = data_tensor.cpu().numpy()\n",
    "    else:\n",
    "        data = data_tensor\n",
    "\n",
    "    # Perform k-means clustering\n",
    "    kmeans = KMeans(n_clusters=k, **kmeans_args).fit(data)\n",
    "\n",
    "    # Extract cluster labels\n",
    "    labels = kmeans.labels_\n",
    "\n",
    "    # Calculate Davies-Bouldin Index\n",
    "    dbi = davies_bouldin_score(data, labels)\n",
    "\n",
    "    return dbi\n",
    "\n",
    "\n",
    "kmeans_args = {\n",
    "    'init': 'k-means++',  # Initialization method\n",
    "    'n_init': 10,         # Number of time the k-means algorithm will run\n",
    "    'max_iter': 300,      # Maximum number of iterations for a single run\n",
    "    'tol': 1e-4,          # Tolerance to declare convergence\n",
    "    'random_state': 666,   # Random state for reproducibility\n",
    "    'algorithm': 'lloyd'   #\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Create a list to store the results\n",
    "results = []\n",
    "\n",
    "# Perform the for loop\n",
    "for k in range(2, 22, 2):\n",
    "    dbi_value_1 = calculate_dbi(\n",
    "        tsne_imagenet_single_template_bert_tiny_uncased, k, **kmeans_args)\n",
    "    dbi_value_2 = calculate_dbi(\n",
    "        tsne_imagenet_single_template_flan_t5_xxl, k, **kmeans_args)\n",
    "    dbi_value_3 = calculate_dbi(\n",
    "        tsne_imagenet_overall_prompt_bert_tiny_uncased, k, **kmeans_args)\n",
    "    dbi_value_4 = calculate_dbi(\n",
    "        tsne_imagenet_overall_prompt_flan_t5_xxl, k, **kmeans_args)\n",
    "    results.append(\n",
    "        [\n",
    "            k,\n",
    "            round(dbi_value_1, 2),\n",
    "            round(dbi_value_2, 2),\n",
    "            round(dbi_value_3, 2),\n",
    "            round(dbi_value_4, 2)\n",
    "        ]\n",
    "    )\n",
    "\n",
    "# Create a dataframe from the results\n",
    "df_results = pd.DataFrame(\n",
    "    results,\n",
    "    columns=['k', 'dbi_value_1', 'dbi_value_2', 'dbi_value_3', 'dbi_value_4']\n",
    ")\n",
    "\n",
    "# Save the dataframe to an xlsx file\n",
    "df_results.to_excel('./results/dbi_comparison.xlsx', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py310openclip",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
